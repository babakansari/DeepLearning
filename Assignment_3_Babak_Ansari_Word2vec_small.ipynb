{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 3 - Babak-Ansari - Word2vec",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/babakansari/DeepLearning/blob/master/Assignment_3_Babak_Ansari_Word2vec_small.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4b5GTVXMBAfC",
        "colab_type": "code",
        "outputId": "45240a3d-803d-429c-d8d5-665a19a53a3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import argparse\n",
        "import collections\n",
        "import hashlib\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "from tempfile import gettempdir\n",
        "import zipfile\n",
        "\n",
        "import numpy as np\n",
        "from six.moves import urllib\n",
        "from six.moves import xrange  # pylint: disable=redefined-builtin\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.contrib.tensorboard.plugins import projector\n",
        "\n",
        "data_index = 0\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HziCjYYiC4BV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Give a folder path as an argument with '--log_dir' to save\n",
        "# TensorBoard summaries. Default is a log folder in current directory.\n",
        "current_path = os.path.dirname(os.path.realpath(sys.argv[0]))\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\n",
        "    '--log_dir',\n",
        "    type=str,\n",
        "    default=os.path.join(current_path, 'log'),\n",
        "    help='The log directory for TensorBoard summaries.')\n",
        "flags, unused_flags = parser.parse_known_args()\n",
        "#word2vec_basic(flags.log_dir)\n",
        "\n",
        "log_dir = flags.log_dir\n",
        "\n",
        "def _hash_file(fpath):\n",
        "  hasher = hashlib.sha256()\n",
        "  with open(fpath, 'rb') as fpath_file:\n",
        "    for chunk in iter(lambda: fpath_file.read(65535), b''):\n",
        "      hasher.update(chunk)\n",
        "  return hasher.hexdigest()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7_AKDaHC4eL",
        "colab_type": "code",
        "outputId": "ec21449d-a633-47b1-ea67-4fa255d086ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "\"\"\"Example of building, training and visualizing a word2vec model.\"\"\"\n",
        "# Create the directory for TensorBoard variables if there is not.\n",
        "if not os.path.exists(log_dir):\n",
        "  os.makedirs(log_dir)\n",
        "\n",
        "# Step 1: Download the data.\n",
        "# Note: Source website does not support HTTPS right now.\n",
        "url = 'http://mattmahoney.net/dc/'\n",
        "\n",
        "# pylint: disable=redefined-outer-name\n",
        "def maybe_download(filename, expected_bytes, sha256=None):\n",
        "  \"\"\"Download a file if not present, and make sure it's the right size.\"\"\"\n",
        "  local_filename = os.path.join(gettempdir(), filename)\n",
        "  if not os.path.exists(local_filename):\n",
        "    local_filename, _ = urllib.request.urlretrieve(url + filename,\n",
        "                                                    local_filename)\n",
        "  statinfo = os.stat(local_filename)\n",
        "\n",
        "  print(local_filename)\n",
        "  if sha256 and _hash_file(local_filename) != sha256:\n",
        "    raise Exception('Failed to verify ' + local_filename + ' due to hash '\n",
        "                    'mismatch. Can you get to it with a browser?')\n",
        "\n",
        "  if statinfo.st_size == expected_bytes:\n",
        "    print('Found and verified', filename)\n",
        "  else:\n",
        "    print(statinfo.st_size)\n",
        "    raise Exception('Failed to verify ' + local_filename +\n",
        "                    '. Can you get to it with a browser?')\n",
        "  return local_filename\n",
        "\n",
        "filename = maybe_download(\n",
        "    'text8.zip',\n",
        "    31344016,\n",
        "    sha256='a6640522afe85d1963ad56c05b0ede0a0c000dddc9671758a6cc09b7a38e5232')\n",
        "\n",
        "# Read the data into a list of strings.\n",
        "def read_data(filename):\n",
        "  \"\"\"Extract the first file enclosed in a zip file as a list of words.\"\"\"\n",
        "  i = 0\n",
        "  with zipfile.ZipFile(filename) as f:\n",
        "    namelist = f.namelist()\n",
        "    r = f.read(namelist[0])\n",
        "    if(i<10):\n",
        "      print(r[:100])\n",
        "      i = i + 1\n",
        "    data = tf.compat.as_str(r).split()\n",
        "  return data\n",
        "\n",
        "vocabulary = read_data(filename)\n",
        "print('Data size', len(vocabulary))\n",
        "\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/tmp/text8.zip\n",
            "Found and verified text8.zip\n",
            "b' anarchism originated as a term of abuse first used against early working class radicals including t'\n",
            "Data size 17005207\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7US35oPQ_oct",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a53bdfd9-3a56-4356-d942-26a4eb21926d"
      },
      "source": [
        "vocabulary = read_data(filename)\n",
        "vocabulary[:4]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b' anarchism originated as a term of abuse first used against early working class radicals including t'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['anarchism', 'originated', 'as', 'a']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6U7Fm-Fhj7lp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eb4fd1f3-7411-4a7f-d6fc-0e0b243f0403"
      },
      "source": [
        "# Try countries as dataset\n",
        "import pandas as pd\n",
        "import io\n",
        "file_name = 'https://github.com/babakansari/DeepLearning/blob/master/Countries.xlsx?raw=true'\n",
        "\n",
        "main_df = pd.read_excel(file_name)\n",
        "df = pd.DataFrame(main_df['Name'].str.lower())\n",
        "vocabulary = df[\"Name\"].tolist()\n",
        "print('Data size', len(vocabulary))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data size 259\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sULmTWNd-738",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "478bc788-1450-45b7-b667-602c85287f66"
      },
      "source": [
        "\n",
        "# vocabulary = df[\"Name\"].tolist()\n",
        "vocabulary = []\n",
        "vocabulary.append('iran')\n",
        "vocabulary.append('iran')\n",
        "vocabulary.append('iran')\n",
        "vocabulary.append('iraq (iq)')\n",
        "vocabulary.append('iran')\n",
        "vocabulary.append('irland')\n",
        "vocabulary.append('irland')\n",
        "vocabulary.append('irland')\n",
        "vocabulary.append('irvan')\n",
        "vocabulary.append('india')\n",
        "vocabulary.append('korea')\n",
        "vocabulary.append('korea')\n",
        "vocabulary.append('korea')\n",
        "vocabulary.append('nigeria')\n",
        "vocabulary.append('russia')\n",
        "vocabulary.append('russia')\n",
        "vocabulary.append('romania')\n",
        "vocabulary.append('rowanda')\n",
        "vocabulary.append('sudan')\n",
        "vocabulary.append('usa')\n",
        "vocabulary.append('korea')\n",
        "print('Data size', len(vocabulary))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data size 21\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5WLX91JJgs7",
        "colab_type": "code",
        "outputId": "284cbce5-d284-4b38-874b-721dec998c05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Step 2: Build the dictionary and replace rare words with UNK token.\n",
        "vocabulary_size = 12\n",
        "\n",
        "def build_dataset(words, n_words):\n",
        "  \"\"\"Process raw inputs into a dataset.\"\"\"\n",
        "  count = [['UNK', -1]]\n",
        "  count.extend(collections.Counter(words).most_common(n_words - 1))\n",
        "  dictionary = {word: index for index, (word, _) in enumerate(count)}\n",
        "  data = []\n",
        "  unk_count = 0\n",
        "  for word in words:\n",
        "    index = dictionary.get(word, 0)\n",
        "    if index == 0:  # dictionary['UNK']\n",
        "      unk_count += 1\n",
        "    data.append(index)\n",
        "  count[0][1] = unk_count\n",
        "  reversed_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
        "  return data, count, dictionary, reversed_dictionary\n",
        "\n",
        "# Filling 4 global variables:\n",
        "# data - list of codes (integers from 0 to vocabulary_size-1).\n",
        "#   This is the original text but words are replaced by their codes\n",
        "# count - map of words(strings) to count of occurrences\n",
        "# dictionary - map of words(strings) to their codes(integers)\n",
        "# reverse_dictionary - map of codes(integers) to words(strings)\n",
        "data, count, unused_dictionary, reverse_dictionary = build_dataset(\n",
        "    vocabulary, vocabulary_size)\n",
        "del vocabulary  # Hint to reduce memory.\n",
        "print('Most common words (+UNK)', count[:5])\n",
        "print('Sample data', data[:10], [reverse_dictionary[i] for i in data[:10]])\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Most common words (+UNK) [['UNK', 1], ('iran', 4), ('korea', 4), ('irland', 3), ('russia', 2)]\n",
            "Sample data [1, 1, 1, 5, 1, 3, 3, 3, 6, 7] ['iran', 'iran', 'iran', 'iraq (iq)', 'iran', 'irland', 'irland', 'irland', 'irvan', 'india']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXMsUlcpDVqY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "9efa4b6f-e5bc-48b8-c1d2-50f771cede2b"
      },
      "source": [
        "count[:7]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['UNK', 1],\n",
              " ('iran', 4),\n",
              " ('korea', 4),\n",
              " ('irland', 3),\n",
              " ('russia', 2),\n",
              " ('iraq (iq)', 1),\n",
              " ('irvan', 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oh0EKYobLA2F",
        "colab_type": "code",
        "outputId": "2deceec6-904d-4f32-dd6b-8dc48aefdff8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# Step 3: Function to generate a training batch for the skip-gram model.\n",
        "def generate_batch(batch_size, num_skips, skip_window):\n",
        "  global data_index\n",
        "  assert batch_size % num_skips == 0\n",
        "  assert num_skips <= 2 * skip_window\n",
        "  batch = np.ndarray(shape=(batch_size), dtype=np.int32)\n",
        "  labels = np.ndarray(shape=(batch_size, 1), dtype=np.int32)\n",
        "  span = 2 * skip_window + 1  # [ skip_window target skip_window ]\n",
        "  buffer = collections.deque(maxlen=span)  # pylint: disable=redefined-builtin\n",
        "  if data_index + span > len(data):\n",
        "    data_index = 0\n",
        "  buffer.extend(data[data_index:data_index + span])\n",
        "  data_index += span\n",
        "  for i in range(batch_size // num_skips):\n",
        "    context_words = [w for w in range(span) if w != skip_window]\n",
        "    words_to_use = random.sample(context_words, num_skips)\n",
        "    for j, context_word in enumerate(words_to_use):\n",
        "      batch[i * num_skips + j] = buffer[skip_window]\n",
        "      labels[i * num_skips + j, 0] = buffer[context_word]\n",
        "    if data_index == len(data):\n",
        "      buffer.extend(data[0:span])\n",
        "      data_index = span\n",
        "    else:\n",
        "      buffer.append(data[data_index])\n",
        "      data_index += 1\n",
        "  # Backtrack a little bit to avoid skipping words in the end of a batch\n",
        "  data_index = (data_index - span) % len(data)\n",
        "  return batch, labels\n",
        "\n",
        "batch, labels = generate_batch(batch_size=8, num_skips=2, skip_window=1)\n",
        "for i in range(8):\n",
        "  print(batch[i], reverse_dictionary[batch[i]], '->', labels[i, 0],\n",
        "        reverse_dictionary[labels[i, 0]])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3 irland -> 3 irland\n",
            "3 irland -> 1 iran\n",
            "3 irland -> 3 irland\n",
            "3 irland -> 3 irland\n",
            "3 irland -> 3 irland\n",
            "3 irland -> 6 irvan\n",
            "6 irvan -> 7 india\n",
            "6 irvan -> 3 irland\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUruLCTmKc75",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "# Step 4: Build and train a skip-gram model.\n",
        "\n",
        "batch_size = 12\n",
        "embedding_size = 12  # Dimension of the embedding vector.\n",
        "skip_window = 5  # How many words to consider left and right.\n",
        "num_skips = 2  # How many times to reuse an input to generate a label.\n",
        "num_sampled = 5  # Number of negative examples to sample.\n",
        "\n",
        "# We pick a random validation set to sample nearest neighbors. Here we limit\n",
        "# the validation samples to the words that have a low numeric ID, which by\n",
        "# construction are also the most frequent. These 3 variables are used only for\n",
        "# displaying model accuracy, they don't affect calculation.\n",
        "valid_size = 3  # Random set of words to evaluate similarity on.\n",
        "valid_window = 8  # Only pick dev samples in the head of the distribution.\n",
        "valid_examples = np.random.choice(valid_window, valid_size, replace=False)\n",
        "\n",
        "graph = tf.Graph()\n",
        "\n",
        "with graph.as_default():\n",
        "\n",
        "  # Input data.\n",
        "  with tf.name_scope('inputs'):\n",
        "    train_inputs = tf.placeholder(tf.int32, shape=[batch_size])\n",
        "    train_labels = tf.placeholder(tf.int32, shape=[batch_size, 1])\n",
        "    valid_dataset = tf.constant(valid_examples, dtype=tf.int32)\n",
        "\n",
        "  # Ops and variables pinned to the CPU because of missing GPU implementation\n",
        "  with tf.device('/cpu:0'):\n",
        "    # Look up embeddings for inputs.\n",
        "    with tf.name_scope('embeddings'):\n",
        "      embeddings = tf.Variable(\n",
        "          tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0))\n",
        "      embed = tf.nn.embedding_lookup(embeddings, train_inputs)\n",
        "\n",
        "    # Construct the variables for the NCE loss\n",
        "    with tf.name_scope('weights'):\n",
        "      nce_weights = tf.Variable(\n",
        "          tf.truncated_normal([vocabulary_size, embedding_size],\n",
        "                              stddev=1.0 / math.sqrt(embedding_size)))\n",
        "    with tf.name_scope('biases'):\n",
        "      nce_biases = tf.Variable(tf.zeros([vocabulary_size]))\n",
        "\n",
        "  # Compute the average NCE loss for the batch.\n",
        "  # tf.nce_loss automatically draws a new sample of the negative labels each\n",
        "  # time we evaluate the loss.\n",
        "  # Explanation of the meaning of NCE loss and why choosing NCE over tf.nn.sampled_softmax_loss:\n",
        "  #   http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/\n",
        "  #   http://papers.nips.cc/paper/5165-learning-word-embeddings-efficiently-with-noise-contrastive-estimation.pdf\n",
        "  with tf.name_scope('loss'):\n",
        "    loss = tf.reduce_mean(\n",
        "        tf.nn.nce_loss(\n",
        "            weights=nce_weights,\n",
        "            biases=nce_biases,\n",
        "            labels=train_labels,\n",
        "            inputs=embed,\n",
        "            num_sampled=num_sampled,\n",
        "            num_classes=vocabulary_size))\n",
        "\n",
        "  # Add the loss value as a scalar to summary.\n",
        "  tf.summary.scalar('loss', loss)\n",
        "\n",
        "  # Construct the SGD optimizer using a learning rate of 1.0.\n",
        "  with tf.name_scope('optimizer'):\n",
        "    optimizer = tf.train.GradientDescentOptimizer(1.0).minimize(loss)\n",
        "\n",
        "  # Compute the cosine similarity between minibatch examples and all\n",
        "  # embeddings.\n",
        "  norm = tf.sqrt(tf.reduce_sum(tf.square(embeddings), 1, keepdims=True))\n",
        "  normalized_embeddings = embeddings / norm\n",
        "  valid_embeddings = tf.nn.embedding_lookup(normalized_embeddings,\n",
        "                                            valid_dataset)\n",
        "  similarity = tf.matmul(\n",
        "      valid_embeddings, normalized_embeddings, transpose_b=True)\n",
        "\n",
        "  # Merge all summaries.\n",
        "  merged = tf.summary.merge_all()\n",
        "\n",
        "  # Add variable initializer.\n",
        "  init = tf.global_variables_initializer()\n",
        "\n",
        "  # Create a saver.\n",
        "  saver = tf.train.Saver()\n",
        "\n",
        "# Step 5: Begin training.\n",
        "num_steps = 10000\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQCo5nHxLbvY",
        "colab_type": "code",
        "outputId": "a17a6460-a34a-43a4-e2e9-f5b1604a0a67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "with tf.compat.v1.Session(graph=graph) as session:\n",
        "  # Open a writer to write summaries.\n",
        "  writer = tf.summary.FileWriter(log_dir, session.graph)\n",
        "\n",
        "  # We must initialize all variables before we use them.\n",
        "  init.run()\n",
        "  print('Initialized')\n",
        "\n",
        "  average_loss = 0\n",
        "  for step in xrange(num_steps):\n",
        "    batch_inputs, batch_labels = generate_batch(batch_size, num_skips,\n",
        "                                                skip_window)\n",
        "    feed_dict = {train_inputs: batch_inputs, train_labels: batch_labels}\n",
        "\n",
        "    # Define metadata variable.\n",
        "    run_metadata = tf.RunMetadata()\n",
        "\n",
        "    # We perform one update step by evaluating the optimizer op (including it\n",
        "    # in the list of returned values for session.run()\n",
        "    # Also, evaluate the merged op to get all summaries from the returned\n",
        "    # \"summary\" variable. Feed metadata variable to session for visualizing\n",
        "    # the graph in TensorBoard.\n",
        "    _, summary, loss_val = session.run([optimizer, merged, loss],\n",
        "                                        feed_dict=feed_dict,\n",
        "                                        run_metadata=run_metadata)\n",
        "    average_loss += loss_val\n",
        "\n",
        "    # Add returned summaries to writer in each step.\n",
        "    writer.add_summary(summary, step)\n",
        "    # Add metadata to visualize the graph for the last run.\n",
        "    if step == (num_steps - 1):\n",
        "      writer.add_run_metadata(run_metadata, 'step%d' % step)\n",
        "\n",
        "    if step % 2000 == 0:\n",
        "      if step > 0:\n",
        "        average_loss /= 2000\n",
        "      # The average loss is an estimate of the loss over the last 2000\n",
        "      # batches.\n",
        "      print('Average loss at step ', step, ': ', average_loss)\n",
        "      average_loss = 0\n",
        "\n",
        "    # Note that this is expensive (~20% slowdown if computed every 500 steps)\n",
        "    if step % 10000 == 0:\n",
        "      sim = similarity.eval()\n",
        "      for i in xrange(valid_size):\n",
        "        valid_word = reverse_dictionary[valid_examples[i]]\n",
        "        top_k = 8  # number of nearest neighbors\n",
        "        nearest = (-sim[i, :]).argsort()[1:top_k + 1]\n",
        "        log_str = 'Nearest to %s:' % valid_word\n",
        "\n",
        "        print(\n",
        "            log_str,\n",
        "            ', '.join([reverse_dictionary[nearest[k]] for k in range(top_k)]))\n",
        "  final_embeddings = normalized_embeddings.eval()\n",
        "\n",
        "  # Write corresponding labels for the embeddings.\n",
        "  with open(log_dir + '/metadata.tsv', 'w') as f:\n",
        "    for i in xrange(vocabulary_size):\n",
        "      f.write(reverse_dictionary[i] + '\\n')\n",
        "\n",
        "  # Save the model for checkpoints.\n",
        "  saver.save(session, os.path.join(log_dir, 'model.ckpt'))\n",
        "\n",
        "  # Create a configuration for visualizing embeddings with the labels in\n",
        "  # TensorBoard.\n",
        "  config = projector.ProjectorConfig()\n",
        "  embedding_conf = config.embeddings.add()\n",
        "  embedding_conf.tensor_name = embeddings.name\n",
        "  embedding_conf.metadata_path = os.path.join(log_dir, 'metadata.tsv')\n",
        "  projector.visualize_embeddings(writer, config)\n",
        "\n",
        "writer.close()\n",
        "\n",
        "# Step 6: Visualize the embeddings.\n",
        "\n",
        "# pylint: disable=missing-docstring\n",
        "# Function to draw visualization of distance between embeddings.\n",
        "def plot_with_labels(low_dim_embs, labels, filename):\n",
        "  assert low_dim_embs.shape[0] >= len(labels), 'More labels than embeddings'\n",
        "  plt.figure(figsize=(18, 18))  # in inches\n",
        "  for i, label in enumerate(labels):\n",
        "    x, y = low_dim_embs[i, :]\n",
        "    plt.scatter(x, y)\n",
        "    plt.annotate(\n",
        "        label,\n",
        "        xy=(x, y),\n",
        "        xytext=(5, 2),\n",
        "        textcoords='offset points',\n",
        "        ha='right',\n",
        "        va='bottom')\n",
        "\n",
        "  plt.savefig(filename)\n",
        "\n",
        "try:\n",
        "  # pylint: disable=g-import-not-at-top\n",
        "  from sklearn.manifold import TSNE\n",
        "  import matplotlib.pyplot as plt\n",
        "\n",
        "  tsne = TSNE(\n",
        "      perplexity=30, n_components=2, init='pca', n_iter=5000, method='exact')\n",
        "  plot_only = 10\n",
        "  low_dim_embs = tsne.fit_transform(final_embeddings[:plot_only, :])\n",
        "  labels = [reverse_dictionary[i] for i in xrange(plot_only)]\n",
        "  plot_with_labels(low_dim_embs, labels, os.path.join(gettempdir(),\n",
        "                                                      'tsne.png'))\n",
        "\n",
        "except ImportError as ex:\n",
        "  print('Please install sklearn, matplotlib, and scipy to show embeddings.')\n",
        "  print(ex)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initialized\n",
            "Average loss at step  0 :  5.797466278076172\n",
            "Nearest to irland: irvan, iran, romania, rowanda, UNK, korea, nigeria, sudan\n",
            "Nearest to iran: irland, irvan, rowanda, UNK, romania, iraq (iq), korea, russia\n",
            "Nearest to india: korea, russia, sudan, iraq (iq), UNK, rowanda, irvan, nigeria\n",
            "Average loss at step  2000 :  2.339272371351719\n",
            "Average loss at step  4000 :  2.3080714413523675\n",
            "Average loss at step  6000 :  2.3087891750335694\n",
            "Average loss at step  8000 :  2.306526431143284\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABBYAAAPxCAYAAABOxC4eAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nztGNXlUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1296x1296 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlr8boYbSNno",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KW3aMaeSm17q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}